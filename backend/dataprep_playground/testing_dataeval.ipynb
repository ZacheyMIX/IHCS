{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5acc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "messy_data_path = '/Users/novellaalvina/Documents/US/UTAH/Lessons/MS/Spring2025/CS 6964/project/IHCS/backend/data/Messy-Data.csv'\n",
    "cleaned_data_path = '/Users/novellaalvina/Documents/US/UTAH/Lessons/MS/Spring2025/CS 6964/project/IHCS/backend/results/final_cleaned_2.csv'\n",
    "openrefine_data_path = '/Users/novellaalvina/Documents/US/UTAH/Lessons/MS/Spring2025/CS 6964/project/IHCS/backend/data/formatted_data_openrefine.csv'\n",
    "gt_data_path = '/Users/novellaalvina/Documents/US/UTAH/Lessons/MS/Spring2025/CS 6964/project/IHCS/backend/data/Cleaned-Data.csv'\n",
    "gt_w_dup_data_path = '/Users/novellaalvina/Documents/US/UTAH/Lessons/MS/Spring2025/CS 6964/project/IHCS/backend/data/cleaned_data_w_duplicates.csv'\n",
    "\n",
    "# Load the files\n",
    "messy_data = pd.read_csv(messy_data_path)\n",
    "ground_truth = pd.read_csv(gt_data_path, index_col=0)\n",
    "ihcs_result = pd.read_csv(cleaned_data_path, index_col=0)\n",
    "openrefine_result = pd.read_csv(openrefine_data_path)\n",
    "gt_w_dup = pd.read_csv(gt_w_dup_data_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240846aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize EmployeeID format to match the pattern in Cleaned-Data.csv\n",
    "def standardize_employee_id(employee_id):\n",
    "    # Remove all non-digit characters\n",
    "    digits_only = re.sub(r'\\D', '', str(employee_id))\n",
    "    \n",
    "    # Check if we have enough digits to format\n",
    "    if len(digits_only) >= 10:\n",
    "        # If the ID doesn't start with 0, add it\n",
    "        if not digits_only.startswith('0'):\n",
    "            digits_only = '0' + digits_only\n",
    "        \n",
    "        # Format as XXXX-XXX-XXX or XXXX-XXX-XXXX depending on length\n",
    "        return f\"{digits_only[:4]}-{digits_only[4:7]}-{digits_only[7:11]}\"\n",
    "    else:\n",
    "        # If not enough digits, pad with zeros at the beginning\n",
    "        padded_digits = digits_only.zfill(10)\n",
    "        return f\"{padded_digits[:4]}-{padded_digits[4:7]}-{padded_digits[7:]}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b8a9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Middle Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Year of Service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Al-Farsi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0426-930-0187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0850-694-271</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   First Name Middle Name Last Name Title     EmployeeID Year of Service\n",
       "2       Ahmed         NaN  Al-Farsi   NaN  0426-930-0187             NaN\n",
       "19       Jane         NaN     Smith   NaN   0850-694-271             NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_w_dup.iloc[[19]] # gtdup.index = 2 : ihcs_res.index = 1\n",
    "                    # gtdup.index = 19 : ihcs_res.index = 21\n",
    "missing_rows_df = gt_w_dup.iloc[[2,19]][['First Name', 'Middle Name', 'Last Name', 'Title', 'EmployeeID', 'Year of Service']]\n",
    "missing_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d82f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_rows_all_columns(missing_rows_df, df_res):\n",
    "    \"\"\" Identify duplicated rows in the ground truth dataframe that has been cleaned and might not be cleaned in the system result and removed them in the system result for preparation before evaluation \"\"\"\n",
    "    \n",
    "    # Reset the index of df_res to create a column with the original indices\n",
    "    df_res_with_index = df_res.reset_index().rename(columns={'index': 'original_index'})\n",
    "\n",
    "    # Perform the merge, which will keep the original_index column\n",
    "    matching_rows = pd.merge(\n",
    "        df_res_with_index, \n",
    "        missing_rows_df, \n",
    "        on=['First Name', 'Middle Name', 'Last Name', 'Title', 'EmployeeID', 'Year of Service'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Now matching_rows contains the original_index column with the indices from df_res\n",
    "    original_indices = matching_rows['original_index'].tolist()\n",
    "\n",
    "    print(f\"The matching rows in df_res have indices: {original_indices}\")\n",
    "\n",
    "    # remove the matching rows in df_res\n",
    "    df_res.drop(original_indices, inplace=True)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6f4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_modified_columns(original_df, cleaned_df):\n",
    "    \"\"\"\n",
    "    Identify columns that were modified during cleaning\n",
    "    \n",
    "    Args:\n",
    "        original_df: The original messy dataframe\n",
    "        cleaned_df: The cleaned dataframe\n",
    "    \n",
    "    Returns:\n",
    "        List of column names that were modified\n",
    "    \"\"\"\n",
    "    modified_columns = []\n",
    "    \n",
    "    # Ensure both dataframes have the same index for comparison\n",
    "    original_df = original_df.reset_index(drop=True)\n",
    "    cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "    \n",
    "    # Check each column for differences\n",
    "    for col in original_df.columns:\n",
    "        if col in cleaned_df.columns:\n",
    "            # Check if the column values are different\n",
    "            if not original_df[col].equals(cleaned_df[col]):\n",
    "                modified_columns.append(col)\n",
    "                \n",
    "    return modified_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2627c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(weight):\n",
    "    weight = weight.split(' ')[0]\n",
    "    w = float(weight)\n",
    "    weight = str(w) + ' lbs'\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3047f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_ihcs(ihcs_res, gt, missing_rows_df):\n",
    "    # make a copy to keep the original\n",
    "    ihcs_res_copy = ihcs_res.copy()\n",
    "    gt_copy = gt.copy()\n",
    "    \n",
    "    # Apply the standardization to the EmployeeID column and Weight\n",
    "    ihcs_res_copy['EmployeeID'] = ihcs_res_copy['EmployeeID'].apply(standardize_employee_id)\n",
    "    gt_copy['Weight'] = gt_copy['Weight'].apply(convert_to_float)\n",
    "\n",
    "    # sort the ground truth dataframe by first name following the ihcs result\n",
    "    gt_fname_sorted = gt_copy.sort_values(by = 'First Name')\n",
    "\n",
    "    # remove duplicated rows\n",
    "    ihcs_result_no_dup = remove_missing_rows_all_columns(missing_rows_df, ihcs_res_copy)\n",
    "    \n",
    "    return gt_fname_sorted, ihcs_result_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d6cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_column_with_duplicates(df, gt, col):\n",
    "    # Make copies to avoid modifying the original dataframes\n",
    "    df = df.copy().reset_index()\n",
    "    gt = gt.copy().reset_index()\n",
    "    \n",
    "    # Merge dataframes on EmployeeID to align rows\n",
    "    merged = pd.merge(gt[['EmployeeID', col]], \n",
    "                     df[['EmployeeID', col]], \n",
    "                     on='EmployeeID', \n",
    "                     how='left',\n",
    "                     suffixes=('_gt', '_cleaned'))\n",
    "    \n",
    "    # Compute correctness\n",
    "    merged['correct'] = (merged[f'{col}_gt'] == merged[f'{col}_cleaned']).astype(int)\n",
    "    \n",
    "    # Create mismatch dataframe\n",
    "    mismatches = merged[merged['correct'] == 0]\n",
    "    mismatch_df = pd.DataFrame({\n",
    "        'EmployeeID': mismatches['EmployeeID'],\n",
    "        'Cleaned': mismatches[f'{col}_cleaned'],\n",
    "        'Solution': mismatches[f'{col}_gt']\n",
    "    })\n",
    "    \n",
    "    return merged['correct'].values, mismatch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a76145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_column_with_metrics(df, gt, col):\n",
    "    \"\"\"\n",
    "    Evaluates a column in the cleaned dataframe against the ground truth with detailed metrics.\n",
    "    \n",
    "    Args:\n",
    "        df: Cleaned dataframe\n",
    "        gt: Ground truth dataframe\n",
    "        col: Column name to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        metrics: Dictionary containing accuracy, precision, recall, and F1 score\n",
    "        mismatch_df: DataFrame showing mismatches between cleaned and ground truth\n",
    "    \"\"\"\n",
    "    # Make copies to avoid modifying the original dataframes\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    gt = gt.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Merge dataframes on EmployeeID to align rows\n",
    "    merged = pd.merge(gt[['EmployeeID', col]], \n",
    "                     df[['EmployeeID', col]], \n",
    "                     on='EmployeeID', \n",
    "                     how='outer',\n",
    "                     suffixes=('_gt', '_cleaned'))\n",
    "    \n",
    "    # Calculate correctness\n",
    "    merged['correct'] = (merged[f'{col}_gt'] == merged[f'{col}_cleaned']).astype(int)\n",
    "    \n",
    "    # Fill NaN values for display in the mismatch dataframe\n",
    "    merged[f'{col}_cleaned'] = merged[f'{col}_cleaned'].fillna('MISSING')\n",
    "    merged[f'{col}_gt'] = merged[f'{col}_gt'].fillna('MISSING')\n",
    "    \n",
    "    # Create mismatch dataframe\n",
    "    mismatches = merged[merged['correct'] == 0]\n",
    "    mismatch_df = pd.DataFrame({\n",
    "        'EmployeeID': mismatches['EmployeeID'],\n",
    "        'Cleaned': mismatches[f'{col}_cleaned'],\n",
    "        'Solution': mismatches[f'{col}_gt']\n",
    "    })\n",
    "    \n",
    "    # Calculate metrics for data cleaning evaluation\n",
    "    total_gt = len(gt)\n",
    "    total_cleaned = len(df)\n",
    "    total_merged = len(merged)\n",
    "    \n",
    "    # Entries present in both datasets\n",
    "    common_entries = merged.dropna(subset=[f'{col}_gt', f'{col}_cleaned']).shape[0]\n",
    "    \n",
    "    # Correct entries (where cleaned matches ground truth)\n",
    "    correct_entries = merged['correct'].sum()\n",
    "    \n",
    "    # Accuracy: proportion of correct entries among all entries\n",
    "    accuracy = correct_entries / total_merged if total_merged > 0 else 0\n",
    "    \n",
    "    # Precision: proportion of correct entries among all entries in cleaned data\n",
    "    # (How many of the cleaned values are correct?)\n",
    "    precision = correct_entries / total_cleaned if total_cleaned > 0 else 0\n",
    "    \n",
    "    # Recall: proportion of ground truth entries that were correctly cleaned\n",
    "    # (How many of the ground truth values did we correctly clean?)\n",
    "    recall = correct_entries / total_gt if total_gt > 0 else 0\n",
    "    \n",
    "    # F1 score: harmonic mean of precision and recall\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'total_gt_entries': total_gt,\n",
    "        'total_cleaned_entries': total_cleaned,\n",
    "        'total_merged_entries': total_merged,\n",
    "        'common_entries': common_entries,\n",
    "        'correct_entries': correct_entries,\n",
    "        'missing_in_cleaned': total_gt - common_entries,\n",
    "        'extra_in_cleaned': total_cleaned - common_entries\n",
    "    }\n",
    "    \n",
    "    return metrics, mismatch_df, merged['correct'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e04d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_modified_columns(df, gt, columns_to_evaluate):\n",
    "    res = {'accuracy': [], 'precision': [], 'recall': [], 'f1score': []}\n",
    "    metrics_dict = {}\n",
    "    for col in columns_to_evaluate:\n",
    "        metrics, _, _ = evaluate_column_with_metrics(df, gt, col)\n",
    "        print(f'{col}: {metrics}')\n",
    "        metrics_dict[col] = metrics\n",
    "        res['accuracy'].append(metrics['accuracy'])\n",
    "        res['precision'].append(metrics['precision'])\n",
    "        res['recall'].append(metrics['recall'])\n",
    "        res['f1score'].append(metrics['f1_score'])\n",
    "        print('')\n",
    "\n",
    "    res['accuracy'] = np.mean(res['accuracy'])\n",
    "    res['precision'] = np.mean(res['precision'])\n",
    "    res['recall'] = np.mean(res['recall'])\n",
    "    res['f1score'] = np.mean(res['f1score'])\n",
    "\n",
    "    return res, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7762cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_openrefine(openrefine_res, gt):\n",
    "    # make a copy to keep the original\n",
    "    openrefine_res_copy = openrefine_res.copy()\n",
    "    gt_copy = gt.copy()\n",
    "    \n",
    "    # apply standardization to EmployeeID and datetime type columns\n",
    "    openrefine_res_copy['EmployeeID'] = openrefine_res_copy['EmployeeID'].apply(standardize_employee_id)\n",
    "    gt_copy['DOB'] = pd.to_datetime(gt_copy['DOB']).dt.strftime('%Y-%m-%dT00:00:00Z')\n",
    "    gt_copy['JoinDate'] = pd.to_datetime(gt_copy['JoinDate']).dt.strftime('%Y-%m-%dT00:00:00Z')\n",
    "\n",
    "    # remove the duplicate rows on openrefine res\n",
    "    openrefine_res_no_dup = openrefine_res_copy.drop([2, 19], axis=0)\n",
    "    \n",
    "    return gt_copy, openrefine_res_no_dup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6a956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_res_df(res_dict):\n",
    "    res_col = []\n",
    "    res_accuracy = []\n",
    "    res_precision = []\n",
    "    res_recall = []\n",
    "    res_f1 = []\n",
    "    \n",
    "    res_data = {'column_name': res_col, 'accuracy': res_accuracy, 'precision': res_precision, 'recall': res_recall, 'f1score': res_f1}\n",
    "    for col, met in res_dict.items():\n",
    "        col_name = col\n",
    "        acc = met['accuracy']\n",
    "        prec = met['precision']\n",
    "        rec = met['recall']\n",
    "        f1 = met['f1_score']\n",
    "        res_col.append(col_name)\n",
    "        res_accuracy.append(acc)\n",
    "        res_precision.append(prec)\n",
    "        res_recall.append(rec)\n",
    "        res_f1.append(f1)\n",
    "    \n",
    "    return pd.DataFrame(res_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4f8ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matching rows in df_res have indices: [1, 21, 22]\n",
      "Columns modified in system result: ['EmployeeID', 'Salary', 'DOB', 'JoinDate', 'Year of Service', 'Weight', 'Address', 'Email']\n",
      "Columns modified in openrefine result: ['Salary', 'DOB', 'JoinDate', 'Email']\n"
     ]
    }
   ],
   "source": [
    "gt_fname_sorted, ihcs_result_no_dup = data_prep_ihcs(ihcs_result, ground_truth, missing_rows_df)\n",
    "gt_modified, openrefine_res_no_dup = data_prep_openrefine(openrefine_result, ground_truth)\n",
    "\n",
    "ihcs_columns_modified = identify_modified_columns(messy_data, ihcs_result_no_dup)\n",
    "openrefine_columns_modified = identify_modified_columns(messy_data, openrefine_result)\n",
    "\n",
    "print(\"Columns modified in system result:\", ihcs_columns_modified)\n",
    "print(\"Columns modified in openrefine result:\", openrefine_columns_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333210e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary: {'accuracy': 0.9791666666666666, 'precision': 1.0, 'recall': 0.9791666666666666, 'f1_score': 0.9894736842105264, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 47, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "DOB: {'accuracy': 0.9375, 'precision': 0.9574468085106383, 'recall': 0.9375, 'f1_score': 0.9473684210526315, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 45, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "JoinDate: {'accuracy': 0.9791666666666666, 'precision': 1.0, 'recall': 0.9791666666666666, 'f1_score': 0.9894736842105264, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 47, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "Year of Service: {'accuracy': 0.4583333333333333, 'precision': 0.46808510638297873, 'recall': 0.4583333333333333, 'f1_score': 0.46315789473684216, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 22, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "Weight: {'accuracy': 0.4791666666666667, 'precision': 0.48936170212765956, 'recall': 0.4791666666666667, 'f1_score': 0.4842105263157895, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 23, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "Address: {'accuracy': 0.8125, 'precision': 0.8297872340425532, 'recall': 0.8125, 'f1_score': 0.8210526315789474, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 39, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "Email: {'accuracy': 0.9791666666666666, 'precision': 1.0, 'recall': 0.9791666666666666, 'f1_score': 0.9894736842105264, 'total_gt_entries': 48, 'total_cleaned_entries': 47, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 47, 'missing_in_cleaned': 0, 'extra_in_cleaned': -1}\n",
      "\n",
      "Salary: {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'total_gt_entries': 48, 'total_cleaned_entries': 48, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 0, 'missing_in_cleaned': 0, 'extra_in_cleaned': 0}\n",
      "\n",
      "DOB: {'accuracy': 0.7291666666666666, 'precision': 0.7291666666666666, 'recall': 0.7291666666666666, 'f1_score': 0.7291666666666665, 'total_gt_entries': 48, 'total_cleaned_entries': 48, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 35, 'missing_in_cleaned': 0, 'extra_in_cleaned': 0}\n",
      "\n",
      "JoinDate: {'accuracy': 0.8541666666666666, 'precision': 0.8541666666666666, 'recall': 0.8541666666666666, 'f1_score': 0.8541666666666666, 'total_gt_entries': 48, 'total_cleaned_entries': 48, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 41, 'missing_in_cleaned': 0, 'extra_in_cleaned': 0}\n",
      "\n",
      "Email: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'total_gt_entries': 48, 'total_cleaned_entries': 48, 'total_merged_entries': 48, 'common_entries': 48, 'correct_entries': 48, 'missing_in_cleaned': 0, 'extra_in_cleaned': 0}\n",
      "\n",
      "ihcs res: {'accuracy': 0.8035714285714286, 'precision': 0.8206686930091186, 'recall': 0.8035714285714286, 'f1score': 0.81203007518797}\n",
      "openrefine res: {'accuracy': 0.6458333333333333, 'precision': 0.6458333333333333, 'recall': 0.6458333333333333, 'f1score': 0.6458333333333333}\n"
     ]
    }
   ],
   "source": [
    "# remove EmployeeID from modified columns\n",
    "ihcs_columns_modified.remove('EmployeeID')\n",
    "\n",
    "# evaluate each modified columns\n",
    "ihcs_res, ihcs_metric_dict = evaluate_all_modified_columns(ihcs_result_no_dup, gt_fname_sorted, ihcs_columns_modified)\n",
    "openrefine_res, openrefine_metric_dict = evaluate_all_modified_columns(openrefine_res_no_dup, gt_modified, openrefine_columns_modified)\n",
    "\n",
    "print(f'ihcs res: {ihcs_res}')\n",
    "print(f'openrefine res: {openrefine_res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c3ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salary</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.989474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOB</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoinDate</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.989474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Year of Service</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.463158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.484211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Address</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.821053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Email</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.989474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column_name  accuracy  precision    recall   f1score\n",
       "0           Salary  0.979167   1.000000  0.979167  0.989474\n",
       "1              DOB  0.937500   0.957447  0.937500  0.947368\n",
       "2         JoinDate  0.979167   1.000000  0.979167  0.989474\n",
       "3  Year of Service  0.458333   0.468085  0.458333  0.463158\n",
       "4           Weight  0.479167   0.489362  0.479167  0.484211\n",
       "5          Address  0.812500   0.829787  0.812500  0.821053\n",
       "6            Email  0.979167   1.000000  0.979167  0.989474"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihcs_res_df = create_res_df(ihcs_metric_dict)\n",
    "openrefine_res_df = create_res_df(openrefine_metric_dict)\n",
    "ihcs_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fede9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOB</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoinDate</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_name  accuracy  precision    recall   f1score\n",
       "0      Salary  0.000000   0.000000  0.000000  0.000000\n",
       "1         DOB  0.729167   0.729167  0.729167  0.729167\n",
       "2    JoinDate  0.854167   0.854167  0.854167  0.854167\n",
       "3       Email  1.000000   1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openrefine_res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
