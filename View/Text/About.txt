Data cleaning is a critical prerequisite for accurate data analysis, yet it is often time-consuming and error-prone.

We present IHCS, an integrated hybrid data cleaning system that automates error detection and repair by combining probabilistic inference with deterministic field-level corrections.

In the preprocessing stage, IHCS monitors for incoming user uploads, formats the input dataset, and transforms user-provided data quality rules into a unified MLN (Markov Logic Network) format. The system then runs probabilistic error detection using Tuffy and flags abnormalities based on learned relationships. After detection, IHCS applies targeted field repairs through Python-based standardization, dynamically interpreting flagged errors without requiring manual intervention.

The visual interface allows users to upload datasets and rules, monitor the cleaning process, and view the final cleaned results both as downloadable files and through dynamic frontend visualization. Users can also see how well the system performed through evaluation metrics (runtime, precision, recall, and F1 score) displayed on the screen.

This project was built as part of the CS 4964/CS 6964: Manage Data for & with ML course at the University of Utah.